import cv2
import numpy as np
import tensorflow as tf
from mediapipe import solutions
import json

# Load the character-to-index map
with open(r'C:\Users\nishi\Videos\MS-ASL\character_to_prediction_index.json', 'r') as f:
    char_to_index = json.load(f)

# Reverse the char_to_index map to get index_to_char
index_to_char = {v: k for k, v in char_to_index.items()}

# Load the TFLite model
interpreter = tf.lite.Interpreter(model_path=r"C:\Users\nishi\Videos\MS-ASL\model.tflite")
interpreter.allocate_tensors()

# Get input and output tensors
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Initialize MediaPipe Holistic for landmark extraction
mp_holistic = solutions.holistic.Holistic(static_image_mode=False, model_complexity=1, enable_segmentation=False, refine_face_landmarks=True)
def extract_landmarks(image):
    # Convert the image from BGR to RGB
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # Perform holistic detection
    results = mp_holistic.process(image_rgb)
    
    # Extract landmarks
    if results.pose_landmarks:
        landmarks = []
        for landmark in results.pose_landmarks.landmark:
            landmarks.extend([landmark.x, landmark.y, landmark.z])
        
        return np.array(landmarks).reshape(1, -1)  # Reshape to match model input shape
    else:
        return None
def predict_landmarks(landmarks):
    # Set the tensor input to the interpreter
    interpreter.set_tensor(input_details[0]['index'], landmarks.astype(np.float32))
    
    # Run inference
    interpreter.invoke()
    
    # Get the prediction output
    output_data = interpreter.get_tensor(output_details[0]['index'])
    
    # Convert output data to characters
    predicted_indices = np.argmax(output_data, axis=-1)
    predicted_chars = [index_to_char[idx] for idx in predicted_indices[0]]
    
    # Return the predicted string
    return "".join(predicted_chars)
def main():
    cap = cv2.VideoCapture(0)  # Open webcam
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        # Extract landmarks from the frame
        landmarks = extract_landmarks(frame)
        
        # If landmarks are detected, make a prediction
        if landmarks is not None:
            prediction = predict_landmarks(landmarks)
            
            # Display the prediction on the frame
            cv2.putText(frame, prediction, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)
        
        # Display the frame
        cv2.imshow('ASL Recognition', frame)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    # Release the webcam and close all windows
    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
